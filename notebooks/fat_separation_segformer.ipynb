{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyORhhZhssTzjmBSULpmNmvT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9vNHvsqmlyTg"},"outputs":[],"source":["# Mount Google Drive (if your data is stored there)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# 필요한 라이브러리 설치 (Google Colab 환경 가정)\n","!pip install transformers"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as TF\n","from sklearn.model_selection import train_test_split\n","\n","# Transformers 라이브러리에서 SegFormer 모델 및 이미지 프로세서를 가져옵니다.\n","from transformers import SegformerForSemanticSegmentation"],"metadata":{"id":"jcEkDCGJkpyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# IoU Loss Function 수정\n","class IoULoss(nn.Module):\n","    def __init__(self, smooth=1e-6):\n","        super(IoULoss, self).__init__()\n","        self.smooth = smooth\n","\n","    def forward(self, inputs, targets):\n","        # Apply sigmoid activation\n","        inputs = torch.sigmoid(inputs)\n","        # Flatten label and prediction tensors\n","        inputs = inputs.view(inputs.size(0), -1)\n","        targets = targets.view(targets.size(0), -1)\n","        # Compute intersection and union\n","        intersection = (inputs * targets).sum(dim=1)\n","        total = (inputs + targets).sum(dim=1)\n","        union = total - intersection\n","        IoU = (intersection + self.smooth) / (union + self.smooth)\n","        return 1 - IoU.mean()"],"metadata":{"id":"eIbr9tFnkrMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 클래스 정의 (이미지와 마스크를 메모리에 로드)\n","class InMemoryDataset(Dataset):\n","    def __init__(self, images, masks, transform=None, mask_transform=None):\n","        self.images = images  # PIL 이미지 리스트\n","        self.masks = masks    # PIL 이미지 리스트\n","        self.transform = transform\n","        self.mask_transform = mask_transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = self.images[idx]\n","        mask = self.masks[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.mask_transform:\n","            mask = self.mask_transform(mask)\n","\n","        return image, mask"],"metadata":{"id":"KOtaufOiks68"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 루프 정의\n","def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n","    best_val_loss = float('inf')\n","    train_losses = []\n","    val_losses = []\n","    best_model_state_dict = None\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","\n","        for images, masks in train_loader:\n","            images = images.to(device)\n","            masks = masks.to(device)\n","\n","            outputs = model(images)\n","            logits = outputs.logits\n","            # 업샘플링 추가\n","            logits = torch.nn.functional.interpolate(logits, size=masks.shape[-2:], mode='bilinear', align_corners=False)\n","\n","            loss = criterion(logits, masks)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item() * images.size(0)\n","\n","        train_loss /= len(train_loader.dataset)\n","\n","        # Validation step\n","        model.eval()\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for images, masks in val_loader:\n","                images = images.to(device)\n","                masks = masks.to(device)\n","\n","                outputs = model(images)\n","                logits = outputs.logits\n","                logits = torch.nn.functional.interpolate(logits, size=masks.shape[-2:], mode='bilinear', align_corners=False)\n","\n","                loss = criterion(logits, masks)\n","\n","                val_loss += loss.item() * images.size(0)\n","\n","        val_loss /= len(val_loader.dataset)\n","\n","        train_losses.append(train_loss)\n","        val_losses.append(val_loss)\n","\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n","\n","        # Save the model\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            best_model_state_dict = model.state_dict()\n","            print(\"Model saved.\")\n","\n","    print(\"Training complete.\")\n","    # Load best model weights\n","    model.load_state_dict(best_model_state_dict)\n","\n","    # Plotting the training and validation loss\n","    plt.figure()\n","    plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n","    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title('Train and Validation Loss')\n","    plt.legend()\n","    plt.savefig('loss_curve.png')\n","    plt.show()\n","\n","    return best_val_loss"],"metadata":{"id":"yNSghQpYkuxR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 로드 및 예측 함수\n","def load_model(model_path, model, device):\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model.eval()\n","    print(\"Model loaded successfully.\")\n","    return model"],"metadata":{"id":"QNHasLMEkwbJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예측 함수 수정\n","def predict(model, image, device):\n","    model.eval()\n","    image = image.to(device).unsqueeze(0)\n","\n","    with torch.no_grad():\n","        outputs = model(image)\n","        logits = outputs.logits\n","        logits = torch.nn.functional.interpolate(logits, size=image.shape[-2:], mode='bilinear', align_corners=False)\n","        probs = torch.sigmoid(logits)\n","        probs = probs.squeeze().cpu().numpy()\n","        output = (probs > 0.5).astype(np.uint8) * 255  # 이진화\n","\n","    return output"],"metadata":{"id":"IN3Sre6UkxwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 평가 지표 계산 함수\n","def compute_metrics(pred, target):\n","    pred = pred.astype(np.uint8).flatten()\n","    target = target.astype(np.uint8).flatten()\n","\n","    intersection = np.sum(pred * target)\n","    union = np.sum(pred) + np.sum(target) - intersection\n","\n","    if union == 0:\n","        iou_score = 1.0  # 만약 예측과 실제값이 모두 0이면 IoU는 1로 설정\n","    else:\n","        iou_score = intersection / union\n","\n","    dice_denominator = np.sum(pred) + np.sum(target)\n","    if dice_denominator == 0:\n","        dice_score = 1.0  # 만약 예측과 실제값이 모두 0이면 Dice 계수는 1로 설정\n","    else:\n","        dice_score = 2 * intersection / dice_denominator\n","\n","    accuracy = np.sum(pred == target) / len(pred)\n","\n","    return iou_score, dice_score, accuracy"],"metadata":{"id":"q6qXpVoJkzW-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 차이 마스크를 생성하는 함수 정의\n","def get_difference_mask(predicted_mask, ground_truth_mask):\n","    # 마스크가 이진 값(0과 255)이라 가정하고 0과 1로 정규화\n","    pred = predicted_mask / 255\n","    gt = ground_truth_mask / 255\n","\n","    # 차이 마스크 생성: 노랑(정확), 빨강(잘못된 양성), 초록(잘못된 음성)\n","    difference = np.zeros((*pred.shape, 3), dtype=np.uint8)\n","    difference[(gt == 1) & (pred == 1)] = [255, 255, 0]  # True Positive - 노랑\n","    difference[(gt == 0) & (pred == 1)] = [255, 0, 0]    # False Positive - 빨강\n","    difference[(gt == 1) & (pred == 0)] = [0, 255, 0]    # False Negative - 초록\n","\n","    return difference"],"metadata":{"id":"HfUCWHQok01b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","if __name__ == '__main__':\n","    import warnings\n","\n","    warnings.filterwarnings(\"ignore\")\n","\n","    # 절대 경로 설정\n","    # In Colab, set base_dir to current working directory\n","    base_dir = '/content/drive/MyDrive/Fat-Protein-Calculation-AI'\n","\n","    # 하이퍼파라미터 및 경로 설정\n","    images_dir = os.path.join(base_dir, 'fat_separation/data')\n","    masks_dir = os.path.join(base_dir, 'fat_separation/mask')\n","    model_path = os.path.join(base_dir, 'best_fat_separation_segformer_model.pth')\n","\n","    num_epochs = 25\n","    batch_size = 2\n","    image_size = (256, 256)\n","\n","    # 허용되는 이미지 확장자 정의\n","    allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n","\n","    # 지정된 디렉토리에서 이미지 파일만 가져오는 함수\n","    def get_image_files(directory):\n","        files = []\n","        for f in os.listdir(directory):\n","            if os.path.splitext(f)[1].lower() in allowed_extensions:\n","                files.append(f)\n","        return files\n","\n","    # 이미지와 마스크 파일 가져오기\n","    image_files = set(get_image_files(images_dir))\n","    mask_files = set(get_image_files(masks_dir))\n","\n","    # 이미지와 마스크의 전체 경로 리스트 생성\n","    image_paths = sorted([os.path.join(images_dir, f) for f in image_files])\n","    mask_paths = sorted([os.path.join(masks_dir, f) for f in mask_files])\n","\n","    # 이미지와 마스크를 메모리에 로드\n","    images_list = []\n","    masks_list = []\n","\n","    for img_path, mask_path in zip(image_paths, mask_paths):\n","        try:\n","            image = Image.open(img_path).convert('RGB')\n","            mask = Image.open(mask_path).convert('L')\n","            images_list.append(image)\n","            masks_list.append(mask)\n","        except Exception as e:\n","            print(f\"이미지 또는 마스크를 로드하는 중 오류 발생: {e}\")\n","            continue\n","\n","    # 데이터 증강 및 증강된 이미지 추가\n","    augmented_images = []\n","    augmented_masks = []\n","\n","    for image, mask in zip(images_list, masks_list):\n","        # 원본 이미지와 마스크 추가\n","        augmented_images.append(image)\n","        augmented_masks.append(mask)\n","\n","        # 랜덤 수평 뒤집기\n","        image_hflip = TF.hflip(image)\n","        mask_hflip = TF.hflip(mask)\n","        augmented_images.append(image_hflip)\n","        augmented_masks.append(mask_hflip)\n","\n","        # 랜덤 수직 뒤집기\n","        image_vflip = TF.vflip(image)\n","        mask_vflip = TF.vflip(mask)\n","        augmented_images.append(image_vflip)\n","        augmented_masks.append(mask_vflip)\n","\n","        # 랜덤 회전\n","        angles = [-30, -15, 15, 30]\n","        for angle in angles:\n","            image_rot = TF.rotate(image, angle, fill=0)\n","            mask_rot = TF.rotate(mask, angle, fill=0)\n","            augmented_images.append(image_rot)\n","            augmented_masks.append(mask_rot)\n","\n","    # 전체 데이터셋의 인덱스 생성\n","    indices = list(range(len(augmented_images)))\n","\n","    # 데이터를 훈련, 검증, 테스트 세트로 분할\n","    train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n","    val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n","\n","    # 분할된 인덱스로 데이터셋 생성\n","    train_images = [augmented_images[i] for i in train_indices]\n","    train_masks = [augmented_masks[i] for i in train_indices]\n","\n","    val_images = [augmented_images[i] for i in val_indices]\n","    val_masks = [augmented_masks[i] for i in val_indices]\n","\n","    test_images = [augmented_images[i] for i in test_indices]\n","    test_masks = [augmented_masks[i] for i in test_indices]\n","\n","    # 데이터 변환 정의\n","    transform = transforms.Compose([\n","        transforms.Resize(image_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","\n","    mask_transform = transforms.Compose([\n","        transforms.Resize(image_size),\n","        transforms.ToTensor()\n","    ])\n","\n","    # 데이터셋 생성\n","    train_dataset = InMemoryDataset(train_images, train_masks, transform=transform, mask_transform=mask_transform)\n","    val_dataset = InMemoryDataset(val_images, val_masks, transform=transform, mask_transform=mask_transform)\n","    test_dataset = InMemoryDataset(test_images, test_masks, transform=transform, mask_transform=mask_transform)\n","\n","    # 모델, 손실 함수, 최적화기 정의\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Hyperparameter tuning\n","    learning_rates = [1e-3, 1e-4, 5e-5]\n","    num_epochs = 25\n","\n","    best_val_loss_overall = float('inf')\n","    best_model_state_dict = None\n","    best_lr = None\n","\n","    for lr in learning_rates:\n","        print(f\"\\nTraining with learning rate: {lr}\")\n","        # SegFormer 모델 초기화\n","        model = SegformerForSemanticSegmentation.from_pretrained(\n","            'nvidia/segformer-b0-finetuned-ade-512-512',\n","            num_labels=1,\n","            ignore_mismatched_sizes=True\n","        ).to(device)\n","        criterion = IoULoss()\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","        val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n","        if val_loss < best_val_loss_overall:\n","            best_val_loss_overall = val_loss\n","            best_model_state_dict = model.state_dict()\n","            best_lr = lr\n","\n","    print(f\"Best learning rate: {best_lr} with validation loss: {best_val_loss_overall}\")\n","    # Save the best model\n","    torch.save(best_model_state_dict, model_path)\n","    print(\"Best model saved.\")\n","\n","    # Load the best model\n","    model = SegformerForSemanticSegmentation.from_pretrained(\n","        'nvidia/segformer-b0-finetuned-ade-512-512',\n","        num_labels=1,\n","        ignore_mismatched_sizes=True\n","    ).to(device)\n","    model.load_state_dict(torch.load(model_path))\n","    print(\"Model loaded successfully.\")\n","\n","    # 데이터로더 생성 (테스트 세트)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","    # 테스트 세트에서 예측 및 평가\n","    iou_scores = []\n","    dice_scores = []\n","    accuracies = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for images, masks in test_loader:\n","            images = images.to(device)\n","            masks = masks.to(device)\n","\n","            outputs = model(images)\n","            logits = outputs.logits\n","            # 업샘플링 추가\n","            logits = torch.nn.functional.interpolate(logits, size=masks.shape[-2:], mode='bilinear', align_corners=False)\n","            preds = torch.sigmoid(logits)\n","            preds = (preds > 0.5).float()\n","\n","            preds_np = preds.cpu().numpy()\n","            masks_np = masks.cpu().numpy()\n","\n","            for pred, mask in zip(preds_np, masks_np):\n","                pred = pred.squeeze()\n","                mask = mask.squeeze()\n","\n","                iou_score, dice_score, accuracy = compute_metrics(pred, mask)\n","                iou_scores.append(iou_score)\n","                dice_scores.append(dice_score)\n","                accuracies.append(accuracy)\n","\n","    mean_iou = np.mean(iou_scores)\n","    mean_dice = np.mean(dice_scores)\n","    mean_accuracy = np.mean(accuracies)\n","\n","    print(f\"\\nTest set metrics:\")\n","    print(f\"Mean IoU: {mean_iou:.4f}\")\n","    print(f\"Mean Dice Coefficient: {mean_dice:.4f}\")\n","    print(f\"Mean Pixel Accuracy: {mean_accuracy:.4f}\")\n","\n","    # 테스트 세트 지표 히스토그램 시각화\n","    plt.figure(figsize=(12, 4))\n","    plt.subplot(1, 3, 1)\n","    plt.hist(iou_scores, bins=20, color='skyblue')\n","    plt.title('IoU Score Distribution')\n","    plt.xlabel('IoU Score')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(1, 3, 2)\n","    plt.hist(dice_scores, bins=20, color='salmon')\n","    plt.title('Dice Coefficient Distribution')\n","    plt.xlabel('Dice Coefficient')\n","    plt.ylabel('Frequency')\n","\n","    plt.subplot(1, 3, 3)\n","    plt.hist(accuracies, bins=20, color='limegreen')\n","    plt.title('Pixel Accuracy Distribution')\n","    plt.xlabel('Pixel Accuracy')\n","    plt.ylabel('Frequency')\n","\n","    plt.tight_layout()\n","    plt.savefig('test_metrics_histogram.png')\n","    plt.show()\n","\n","    # 테스트 세트에서 일부 샘플 시각화\n","    num_samples_to_visualize = 3\n","    samples_indices = np.random.choice(len(test_dataset), num_samples_to_visualize, replace=False)\n","\n","    for idx in samples_indices:\n","        test_image, test_mask = test_dataset[idx]\n","        predicted_mask = predict(model, test_image, device)\n","\n","        # 시각화를 위한 이미지 역정규화\n","        inv_normalize = transforms.Normalize(\n","            mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225],\n","            std=[1 / 0.229, 1 / 0.224, 1 / 0.225]\n","        )\n","        test_image_vis = inv_normalize(test_image).permute(1, 2, 0).numpy()\n","        test_image_vis = np.clip(test_image_vis, 0, 1)\n","\n","        # 마스크를 이진 numpy 배열로 변환\n","        test_mask_np = (test_mask.squeeze().cpu().numpy() > 0.5).astype(np.uint8) * 255\n","        predicted_mask_np = (predicted_mask > 0.5).astype(np.uint8) * 255\n","\n","        # 차이 마스크 생성\n","        difference_mask = get_difference_mask(predicted_mask_np, test_mask_np)\n","\n","        # 원본 이미지, Ground Truth, Predicted Mask, 차이 마스크 시각화\n","        plt.figure(figsize=(20, 5))\n","\n","        plt.subplot(1, 4, 1)\n","        plt.title(\"Original Image\")\n","        plt.imshow(test_image_vis)\n","        plt.axis('off')\n","\n","        plt.subplot(1, 4, 2)\n","        plt.title(\"Ground Truth Mask\")\n","        plt.imshow(test_mask_np, cmap='gray')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 4, 3)\n","        plt.title(\"Predicted Mask\")\n","        plt.imshow(predicted_mask_np, cmap='gray')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 4, 4)\n","        plt.title(\"Difference\")\n","        plt.imshow(difference_mask)\n","        plt.axis('off')\n","\n","        plt.show()"],"metadata":{"id":"nLSaTy-yk2N_"},"execution_count":null,"outputs":[]}]}